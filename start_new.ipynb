{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHd6YvhSWVvuc0NywXmDvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siva-training/auto_coding/blob/master/start_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqo_Gj87_Iql"
      },
      "source": [
        "Install all required software"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW8FZCsiojuV",
        "outputId": "144cb935-3f75-43af-ec6f-b4018198d5b0"
      },
      "source": [
        "!apt install git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P46D1LXbon-U",
        "outputId": "35f0b3a7-6b3c-494a-e9f9-ec7cdf540e9e"
      },
      "source": [
        "!git clone https://github.com/siva-training/auto_coding.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'auto_coding'...\n",
            "remote: Enumerating objects: 966, done.\u001b[K\n",
            "remote: Counting objects: 100% (966/966), done.\u001b[K\n",
            "remote: Compressing objects: 100% (680/680), done.\u001b[K\n",
            "remote: Total 966 (delta 250), reused 919 (delta 220), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (966/966), 1.01 MiB | 7.10 MiB/s, done.\n",
            "Resolving deltas: 100% (250/250), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDRT9B1bo2gi",
        "outputId": "bbf5755c-9504-4846-a7bd-2cee2579bb35"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 6 root root 4096 Sep  9 12:57 \u001b[0m\u001b[01;34mauto_coding\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Sep  1 19:26 \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "84tyv0ngo43c",
        "outputId": "7bddabb4-bd94-40ec-ba44-47051b47dd7a"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrbIkc54_Mdr",
        "outputId": "4bd80b72-1222-4e3f-f458-18c4d4e6209f"
      },
      "source": [
        "!sudo apt install python3-pip "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
            "  python3-wheel python3-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
            "  python3-six python3-wheel python3-xdg\n",
            "0 upgraded, 15 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 2,882 kB of archives.\n",
            "After this operation, 8,886 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Fetched 2,882 kB in 1s (2,095 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 148492 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZUGEg4j_Ovg"
      },
      "source": [
        "Get CUDA version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm94GjZb_PiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daaa26ba-b390-46cb-b6f7-b6fc742465ed"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ia7txY_U87"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWjgqUfWr65X",
        "outputId": "c3a7683a-2b27-4cef-912b-a9fc8095c195"
      },
      "source": [
        "!pip uninstall torchtext -y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchtext 0.10.0\n",
            "Uninstalling torchtext-0.10.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/torchtext-0.10.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torchtext/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0c_zmaZ_VpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73518dab-7038-4e30-93d3-5e5c82a482c8"
      },
      "source": [
        "!pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio==0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
            "Collecting torch==1.8.2+cu111\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cu111/torch-1.8.2%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.5 MB/s eta 0:12:26tcmalloc: large alloc 1147494400 bytes == 0x55ff64332000 @  0x7f7f113fb615 0x55ff2acff02c 0x55ff2addf17a 0x55ff2ad01e4d 0x55ff2adf3c0d 0x55ff2ad760d8 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad75f40 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2ad03b99 0x55ff2ad46e79 0x55ff2ad027b2 0x55ff2ad75e65 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71b0e 0x55ff2ad0365a 0x55ff2ad71d67 0x55ff2ad70c35\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 33.7 MB/s eta 0:00:28tcmalloc: large alloc 1434370048 bytes == 0x55ffa8988000 @  0x7f7f113fb615 0x55ff2acff02c 0x55ff2addf17a 0x55ff2ad01e4d 0x55ff2adf3c0d 0x55ff2ad760d8 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad75f40 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2ad03b99 0x55ff2ad46e79 0x55ff2ad027b2 0x55ff2ad75e65 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71b0e 0x55ff2ad0365a 0x55ff2ad71d67 0x55ff2ad70c35\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.5 MB/s eta 0:07:14tcmalloc: large alloc 1792966656 bytes == 0x55ff2d7ba000 @  0x7f7f113fb615 0x55ff2acff02c 0x55ff2addf17a 0x55ff2ad01e4d 0x55ff2adf3c0d 0x55ff2ad760d8 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad75f40 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2ad03b99 0x55ff2ad46e79 0x55ff2ad027b2 0x55ff2ad75e65 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71b0e 0x55ff2ad0365a 0x55ff2ad71d67 0x55ff2ad70c35\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.3 MB/s eta 0:03:41tcmalloc: large alloc 2241208320 bytes == 0x55ff985a2000 @  0x7f7f113fb615 0x55ff2acff02c 0x55ff2addf17a 0x55ff2ad01e4d 0x55ff2adf3c0d 0x55ff2ad760d8 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad75f40 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2adf4a56 0x55ff2ad71fb3 0x55ff2ad03b99 0x55ff2ad46e79 0x55ff2ad027b2 0x55ff2ad75e65 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71b0e 0x55ff2ad0365a 0x55ff2ad71d67 0x55ff2ad70c35\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.5 MB/s eta 0:00:01tcmalloc: large alloc 1982201856 bytes == 0x56001df04000 @  0x7f7f113fa1e7 0x55ff2ad34ae7 0x55ff2acff02c 0x55ff2addf17a 0x55ff2ad01e4d 0x55ff2adf3c0d 0x55ff2ad760d8 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad0365a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35\n",
            "tcmalloc: large alloc 2477752320 bytes == 0x56010858e000 @  0x7f7f113fb615 0x55ff2acff02c 0x55ff2addf17a 0x55ff2ad01e4d 0x55ff2adf3c0d 0x55ff2ad760d8 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad71d67 0x55ff2ad0365a 0x55ff2ad71d67 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35 0x55ff2ad0373a 0x55ff2ad7293b 0x55ff2ad70c35 0x55ff2ad03dd1\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 3.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.2+cu111\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cu111/torchvision-0.9.2%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.5 MB 113 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.2\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/torchaudio-0.8.2-cp37-cp37m-linux_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 27.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.2+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.2+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.2+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.2+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.2+cu111 torchaudio-0.8.2 torchvision-0.9.2+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbXw4_PCqszw",
        "outputId": "1186b0a3-9485-415c-ba87-c5df8ebaaf6a"
      },
      "source": [
        "cd auto_coding"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'auto_coding'\n",
            "/content/auto_coding/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRaPt9UTqy6U",
        "outputId": "148af4e7-32a5-4d82-8052-407a2891be4c"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.62.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.8.2+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.1-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.2->-r requirements.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (21.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (4.6.4)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->-r requirements.txt (line 3)) (2.4.7)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 6)) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 6)) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 6)) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 6)) (3.17.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=2162a75fdb1cceb875950ca94644d6bd653fba7ca0ceddf8f692f0b656a4453d\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=98ab36e8567c39b26dc39ec55b2bdda2482f5e5cfbef29d5ee671a881e092bc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, tokenizers, subprocess32, shortuuid, sentry-sdk, sacremoses, pyyaml, pathtools, huggingface-hub, GitPython, docker-pycreds, configparser, wandb, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 huggingface-hub-0.0.16 pathtools-0.1.2 pyyaml-5.4.1 sacremoses-0.0.45 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 tokenizers-0.10.3 transformers-4.10.0 wandb-0.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxkcUkcGq14B",
        "outputId": "65798c76-73d7-478c-e4fd-25b4214cada4"
      },
      "source": [
        "cd dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/auto_coding/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaxbkVY-0Ltf",
        "outputId": "cc8dc45e-d984-4917-ed83-7f20104a1358"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "-rw-r--r-- 1 root root 2208 Sep  9 13:45 convert.py\n",
            "-rw-r--r-- 1 root root 1127 Sep  9 13:45 README.md\n",
            "drwxr-xr-x 7 root root 4096 Sep  9 13:51 \u001b[0m\u001b[01;34mTerraformRepo\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ranhfx6t2yV",
        "outputId": "daccbff4-f2bc-4a85-f87f-15870a49d446"
      },
      "source": [
        "!git clone https://github.com/prodapt-cloud/TerraformRepo.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TerraformRepo'...\n",
            "remote: Enumerating objects: 948, done.\u001b[K\n",
            "remote: Counting objects: 100% (948/948), done.\u001b[K\n",
            "remote: Compressing objects: 100% (651/651), done.\u001b[K\n",
            "remote: Total 948 (delta 245), reused 915 (delta 229), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (948/948), 627.61 KiB | 6.21 MiB/s, done.\n",
            "Resolving deltas: 100% (245/245), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCnYWBqFt1Hb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saVeR6-Iq-k7",
        "outputId": "50e66f0f-9103-4f4e-da1f-9ad617c4b697"
      },
      "source": [
        "!sudo python3 convert.py --segment_len 256 --stride 10 --dev_size 0.1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 6.86MB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 4.20MB/s]\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 7.48MB/s]\n",
            "Downloading: 100% 665/665 [00:00<00:00, 679kB/s]\n",
            "  0% 0/5916 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2454 > 1024). Running this sequence through the model will result in indexing errors\n",
            "100% 5916/5916 [00:31<00:00, 189.74it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TETIY1ov4Z9",
        "outputId": "937120a3-a3b9-42bd-c62c-4f0e925bd5a8"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/auto_coding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDwAD2YcrEN1",
        "outputId": "211ccf86-3728-4bbf-c5d3-429a99d106f0"
      },
      "source": [
        "\n",
        "!sudo python3 train.py --model_select distilgpt2"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "INFO:__main__:args: Namespace(accumulation_steps=1, dataset_name='source_code', dev_batch_size=8, early_stop=20, evaluation_steps=200, lr=2e-05, max_seq_length=256, model_select='distilgpt2', n_gpu=1, num_epochs_train=16, per_gpu_train_batch_size=4, restore_training=False, scheduler='warmuplinear', seed=122, visiable_device='0', wandb_project_name='code_generate', warmup_ratio=0.2, with_wandb=False)\n",
            "INFO:__main__:model/distilgpt2_fine_tuned_coder for dataset in: dataset/source_code/json/\n",
            "INFO:__main__:*****************model select: distilgpt2 for code generation using dataset: source_code******************\n",
            "INFO:filelock:Lock 140274635337360 acquired on /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631.lock\n",
            "Downloading: 100% 762/762 [00:00<00:00, 639kB/s]\n",
            "INFO:filelock:Lock 140274635337360 released on /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631.lock\n",
            "INFO:filelock:Lock 140274609748496 acquired on /root/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba.lock\n",
            "Downloading: 100% 353M/353M [00:08<00:00, 43.8MB/s]\n",
            "INFO:filelock:Lock 140274609748496 released on /root/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba.lock\n",
            "INFO:filelock:Lock 140274603079696 acquired on /root/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f.lock\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 5.62MB/s]\n",
            "INFO:filelock:Lock 140274603079696 released on /root/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f.lock\n",
            "INFO:filelock:Lock 140274602950864 acquired on /root/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 2.88MB/s]\n",
            "INFO:filelock:Lock 140274602950864 released on /root/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
            "INFO:filelock:Lock 140274602953680 acquired on /root/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0.lock\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 6.65MB/s]\n",
            "INFO:filelock:Lock 140274602953680 released on /root/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0.lock\n",
            "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "390941it [01:32, 4224.37it/s]\n",
            "INFO:data:  save tokenized ids of samples to: .cache/model/distilgpt2_fine_tuned_coder/train/inputs.pk\n",
            "43438it [00:11, 3906.18it/s]\n",
            "INFO:data:  save tokenized ids of samples to: .cache/model/distilgpt2_fine_tuned_coder/dev/inputs.pk\n",
            "WARNING:trainer:no cuda is found in your machine, now use cpu\n",
            "INFO:trainer:Use pytorch device: cpu, with gpu_number=0\n",
            "INFO:trainer:   see seed for random, numpy and torch 122\n",
            "INFO:trainer:gpt.transformer.wte.weight\ttorch.Size([50260, 768])\n",
            "INFO:trainer:gpt.transformer.wpe.weight\ttorch.Size([1024, 768])\n",
            "INFO:trainer:gpt.transformer.h.0.ln_1.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.0.ln_1.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.0.attn.bias\ttorch.Size([1, 1, 1024, 1024])\n",
            "INFO:trainer:gpt.transformer.h.0.attn.masked_bias\ttorch.Size([])\n",
            "INFO:trainer:gpt.transformer.h.0.attn.c_attn.weight\ttorch.Size([768, 2304])\n",
            "INFO:trainer:gpt.transformer.h.0.attn.c_attn.bias\ttorch.Size([2304])\n",
            "INFO:trainer:gpt.transformer.h.0.attn.c_proj.weight\ttorch.Size([768, 768])\n",
            "INFO:trainer:gpt.transformer.h.0.attn.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.0.ln_2.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.0.ln_2.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.0.mlp.c_fc.weight\ttorch.Size([768, 3072])\n",
            "INFO:trainer:gpt.transformer.h.0.mlp.c_fc.bias\ttorch.Size([3072])\n",
            "INFO:trainer:gpt.transformer.h.0.mlp.c_proj.weight\ttorch.Size([3072, 768])\n",
            "INFO:trainer:gpt.transformer.h.0.mlp.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.1.ln_1.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.1.ln_1.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.1.attn.bias\ttorch.Size([1, 1, 1024, 1024])\n",
            "INFO:trainer:gpt.transformer.h.1.attn.masked_bias\ttorch.Size([])\n",
            "INFO:trainer:gpt.transformer.h.1.attn.c_attn.weight\ttorch.Size([768, 2304])\n",
            "INFO:trainer:gpt.transformer.h.1.attn.c_attn.bias\ttorch.Size([2304])\n",
            "INFO:trainer:gpt.transformer.h.1.attn.c_proj.weight\ttorch.Size([768, 768])\n",
            "INFO:trainer:gpt.transformer.h.1.attn.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.1.ln_2.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.1.ln_2.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.1.mlp.c_fc.weight\ttorch.Size([768, 3072])\n",
            "INFO:trainer:gpt.transformer.h.1.mlp.c_fc.bias\ttorch.Size([3072])\n",
            "INFO:trainer:gpt.transformer.h.1.mlp.c_proj.weight\ttorch.Size([3072, 768])\n",
            "INFO:trainer:gpt.transformer.h.1.mlp.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.2.ln_1.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.2.ln_1.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.2.attn.bias\ttorch.Size([1, 1, 1024, 1024])\n",
            "INFO:trainer:gpt.transformer.h.2.attn.masked_bias\ttorch.Size([])\n",
            "INFO:trainer:gpt.transformer.h.2.attn.c_attn.weight\ttorch.Size([768, 2304])\n",
            "INFO:trainer:gpt.transformer.h.2.attn.c_attn.bias\ttorch.Size([2304])\n",
            "INFO:trainer:gpt.transformer.h.2.attn.c_proj.weight\ttorch.Size([768, 768])\n",
            "INFO:trainer:gpt.transformer.h.2.attn.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.2.ln_2.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.2.ln_2.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.2.mlp.c_fc.weight\ttorch.Size([768, 3072])\n",
            "INFO:trainer:gpt.transformer.h.2.mlp.c_fc.bias\ttorch.Size([3072])\n",
            "INFO:trainer:gpt.transformer.h.2.mlp.c_proj.weight\ttorch.Size([3072, 768])\n",
            "INFO:trainer:gpt.transformer.h.2.mlp.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.3.ln_1.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.3.ln_1.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.3.attn.bias\ttorch.Size([1, 1, 1024, 1024])\n",
            "INFO:trainer:gpt.transformer.h.3.attn.masked_bias\ttorch.Size([])\n",
            "INFO:trainer:gpt.transformer.h.3.attn.c_attn.weight\ttorch.Size([768, 2304])\n",
            "INFO:trainer:gpt.transformer.h.3.attn.c_attn.bias\ttorch.Size([2304])\n",
            "INFO:trainer:gpt.transformer.h.3.attn.c_proj.weight\ttorch.Size([768, 768])\n",
            "INFO:trainer:gpt.transformer.h.3.attn.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.3.ln_2.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.3.ln_2.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.3.mlp.c_fc.weight\ttorch.Size([768, 3072])\n",
            "INFO:trainer:gpt.transformer.h.3.mlp.c_fc.bias\ttorch.Size([3072])\n",
            "INFO:trainer:gpt.transformer.h.3.mlp.c_proj.weight\ttorch.Size([3072, 768])\n",
            "INFO:trainer:gpt.transformer.h.3.mlp.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.4.ln_1.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.4.ln_1.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.4.attn.bias\ttorch.Size([1, 1, 1024, 1024])\n",
            "INFO:trainer:gpt.transformer.h.4.attn.masked_bias\ttorch.Size([])\n",
            "INFO:trainer:gpt.transformer.h.4.attn.c_attn.weight\ttorch.Size([768, 2304])\n",
            "INFO:trainer:gpt.transformer.h.4.attn.c_attn.bias\ttorch.Size([2304])\n",
            "INFO:trainer:gpt.transformer.h.4.attn.c_proj.weight\ttorch.Size([768, 768])\n",
            "INFO:trainer:gpt.transformer.h.4.attn.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.4.ln_2.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.4.ln_2.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.4.mlp.c_fc.weight\ttorch.Size([768, 3072])\n",
            "INFO:trainer:gpt.transformer.h.4.mlp.c_fc.bias\ttorch.Size([3072])\n",
            "INFO:trainer:gpt.transformer.h.4.mlp.c_proj.weight\ttorch.Size([3072, 768])\n",
            "INFO:trainer:gpt.transformer.h.4.mlp.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.5.ln_1.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.5.ln_1.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.5.attn.bias\ttorch.Size([1, 1, 1024, 1024])\n",
            "INFO:trainer:gpt.transformer.h.5.attn.masked_bias\ttorch.Size([])\n",
            "INFO:trainer:gpt.transformer.h.5.attn.c_attn.weight\ttorch.Size([768, 2304])\n",
            "INFO:trainer:gpt.transformer.h.5.attn.c_attn.bias\ttorch.Size([2304])\n",
            "INFO:trainer:gpt.transformer.h.5.attn.c_proj.weight\ttorch.Size([768, 768])\n",
            "INFO:trainer:gpt.transformer.h.5.attn.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.5.ln_2.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.5.ln_2.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.h.5.mlp.c_fc.weight\ttorch.Size([768, 3072])\n",
            "INFO:trainer:gpt.transformer.h.5.mlp.c_fc.bias\ttorch.Size([3072])\n",
            "INFO:trainer:gpt.transformer.h.5.mlp.c_proj.weight\ttorch.Size([3072, 768])\n",
            "INFO:trainer:gpt.transformer.h.5.mlp.c_proj.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.ln_f.weight\ttorch.Size([768])\n",
            "INFO:trainer:gpt.transformer.ln_f.bias\ttorch.Size([768])\n",
            "INFO:trainer:gpt.lm_head.weight\ttorch.Size([50260, 768])\n",
            "INFO:trainer:GPTSingleHead(\n",
            "  (gpt): GPT2LMHeadModel(\n",
            "    (transformer): GPT2Model(\n",
            "      (wte): Embedding(50260, 768)\n",
            "      (wpe): Embedding(1024, 768)\n",
            "      (drop): Dropout(p=0.1, inplace=False)\n",
            "      (h): ModuleList(\n",
            "        (0): GPT2Block(\n",
            "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): GPT2Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): GPT2MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): GPT2Block(\n",
            "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): GPT2Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): GPT2MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): GPT2Block(\n",
            "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): GPT2Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): GPT2MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): GPT2Block(\n",
            "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): GPT2Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): GPT2MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): GPT2Block(\n",
            "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): GPT2Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): GPT2MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): GPT2Block(\n",
            "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): GPT2Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): GPT2MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
            "  )\n",
            ")\n",
            "INFO:trainer:EmptyHeads()\n",
            "INFO:trainer:  Total params: 81914880\n",
            "INFO:trainer:  Trainable params: 81914880\n",
            "INFO:trainer:  Non-trainable params: 0\n",
            "INFO:trainer:   Warmup-steps: 312756\n",
            "INFO:trainer:***** Running training *****\n",
            "INFO:trainer:  Num of training examples (actually iterations per epoch for Iterable Dataset) = 390941\n",
            "INFO:trainer:  Output path (short): tmp/model/distilgpt2_fine_tuned_coder\n",
            "INFO:trainer:  Steps per Epoch = 97736 or iterations per epoch = 97736\n",
            "INFO:trainer:  Num of Epochs = 16\n",
            "INFO:trainer:  Best score (perplexity) = -inf\n",
            "INFO:trainer:  Eval every 200 steps or every 200 iterations\n",
            "INFO:trainer:  Early stop = 20\n",
            "INFO:trainer:  Gradient Accumulation steps = 1\n",
            "INFO:trainer:  Total optimization steps = 1563776\n",
            "INFO:trainer:  Instantaneous batch size per GPU = 4 and n_gpu = 0 so the input batch size = 4\n",
            "Epoch:   0% 0/16 [00:00<?, ?it/s]\n",
            "training:   0% 0/97736 [00:00<?, ?it/s]\u001b[A\n",
            "training:   0% 1/97736 [00:42<1150:00:20, 42.36s/it]\u001b[A\n",
            "training:   0% 2/97736 [01:21<1095:58:41, 40.37s/it]\u001b[A\n",
            "training:   0% 3/97736 [01:46<912:13:12, 33.60s/it] \u001b[A\n",
            "training:   0% 4/97736 [02:24<978:00:24, 36.03s/it]\n",
            "Epoch:   0% 0/16 [02:24<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 104, in <module>\n",
            "    model_trainer.train()\n",
            "  File \"/content/auto_coding/trainer.py\", line 492, in train\n",
            "    epoch_loss, epoch_steps = self._train_epoch(epoch, global_steps)\n",
            "  File \"/content/auto_coding/trainer.py\", line 375, in _train_epoch\n",
            "    loss_value, _ = self.model(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 119, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/auto_coding/model.py\", line 49, in forward\n",
            "    loss, logits=self.gpt(input[\"input_ids\"],labels=input[\"input_ids\"])[:2]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 962, in forward\n",
            "    return_dict=return_dict,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 801, in forward\n",
            "    output_attentions=output_attentions,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 355, in forward\n",
            "    feed_forward_hidden_states = self.mlp(hidden_states)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 282, in forward\n",
            "    hidden_states = self.c_fc(hidden_states)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\", line 1601, in forward\n",
            "    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd42OeaBuIjT",
        "outputId": "9f8d2fdd-c315-4077-fc46-8fc0458ac810"
      },
      "source": [
        "!pip install deepspeed"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.5.1.tar.gz (476 kB)\n",
            "\u001b[K     |████████████████████████████████| 476 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.62.0)\n",
            "Collecting tensorboardX==1.8\n",
            "  Downloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.0)\n",
            "Collecting triton\n",
            "  Downloading triton-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 36 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->deepspeed) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed) (2.4.7)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.5.1-py3-none-any.whl size=479292 sha256=463468a21fb8ce083f0f04af9cd448f2ca3d16d696e1887fa99d301da7852fc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/e0/d4/7d3a99f5cc143c5ea0379218816586ca41838770880c69ac55\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: triton, tensorboardX, ninja, deepspeed\n",
            "Successfully installed deepspeed-0.5.1 ninja-1.10.2 tensorboardX-1.8 triton-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxlRepDjuSir"
      },
      "source": [
        "get architecture list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNc8p_DMuZxb",
        "outputId": "7dc42a2c-6f47-4529-f1a7-70cf187524ed"
      },
      "source": [
        "CUDA_VISIBLE_DEVICES=0 \n",
        "!python3 -c \"import torch; print(torch.cuda.get_device_capability())\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH1AhMt3zWUN",
        "outputId": "fc275cc7-07d8-4bbd-a3b6-a47c95a0d5d4"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 628\n",
            "-rw-r--r-- 1 root root   5742 Sep  9 13:45 autocoding_collab.ipynb\n",
            "-rw-r--r-- 1 root root   2882 Sep  9 13:45 data.py\n",
            "drwxr-xr-x 5 root root   4096 Sep  9 13:54 \u001b[0m\u001b[01;34mdataset\u001b[0m/\n",
            "-rw-r--r-- 1 root root 401096 Sep  9 13:45 demo.gif\n",
            "-rw-r--r-- 1 root root  17851 Sep  9 13:45 distillgpt2.ipynb\n",
            "-rw-r--r-- 1 root root   2765 Sep  9 13:45 evaluate.py\n",
            "-rw-r--r-- 1 root root 117864 Sep  9 13:45 hf_model.png\n",
            "-rw-r--r-- 1 root root   3442 Sep  9 13:45 icon.png\n",
            "-rw-r--r-- 1 root root   2515 Sep  9 13:45 interact.py\n",
            "-rw-r--r-- 1 root root  11324 Sep  9 13:45 LICENSE\n",
            "-rw-r--r-- 1 root root   5764 Sep  9 13:45 model.py\n",
            "drwxr-xr-x 3 root root   4096 Sep  9 13:45 \u001b[01;34mpynb\u001b[0m/\n",
            "-rw-r--r-- 1 root root   7160 Sep  9 13:45 README.md\n",
            "-rw-r--r-- 1 root root     63 Sep  9 13:45 requirements.txt\n",
            "-rw-r--r-- 1 root root  27998 Sep  9 13:45 trainer.py\n",
            "-rw-r--r-- 1 root root   5749 Sep  9 13:45 train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-jIiy7s220G"
      },
      "source": [
        "%%bash\n",
        "cat <<'EOT' > ds_config_zero3.json\n",
        "{\n",
        "    \"fp16\": {\n",
        "        \"enabled\": \"auto\",\n",
        "        \"loss_scale\": 0,\n",
        "        \"loss_scale_window\": 1000,\n",
        "        \"initial_scale_power\": 16,\n",
        "        \"hysteresis\": 2,\n",
        "        \"min_loss_scale\": 1\n",
        "    },\n",
        "\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"params\": {\n",
        "            \"lr\": \"auto\",\n",
        "            \"betas\": \"auto\",\n",
        "            \"eps\": \"auto\",\n",
        "            \"weight_decay\": \"auto\"\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"WarmupLR\",\n",
        "        \"params\": {\n",
        "            \"warmup_min_lr\": \"auto\",\n",
        "            \"warmup_max_lr\": \"auto\",\n",
        "            \"warmup_num_steps\": \"auto\"\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 3,\n",
        "        \"offload_optimizer\": {\n",
        "            \"device\": \"cpu\",\n",
        "            \"pin_memory\": true\n",
        "        },\n",
        "        \"offload_param\": {\n",
        "            \"device\": \"cpu\",\n",
        "            \"pin_memory\": true\n",
        "        },\n",
        "        \"overlap_comm\": true,\n",
        "        \"contiguous_gradients\": true,\n",
        "        \"sub_group_size\": 1e9,\n",
        "        \"reduce_bucket_size\": \"auto\",\n",
        "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
        "        \"stage3_param_persistence_threshold\": \"auto\",\n",
        "        \"stage3_max_live_parameters\": 1e9,\n",
        "        \"stage3_max_reuse_distance\": 1e9,\n",
        "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
        "    },\n",
        "\n",
        "    \"gradient_accumulation_steps\": \"auto\",\n",
        "    \"gradient_clipping\": \"auto\",\n",
        "    \"steps_per_print\": 2000,\n",
        "    \"train_batch_size\": \"auto\",\n",
        "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
        "    \"wall_clock_breakdown\": false\n",
        "}\n",
        "EOT"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4t7iXCvyxLd",
        "outputId": "df112508-84f1-4444-a7f5-5cd7980407a9"
      },
      "source": [
        "!sudo deepspeed train.py --model_select distilgpt2"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-09-09 13:54:39,785] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2021-09-09 13:54:39,938] [INFO] [runner.py:360:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train.py --model_select distilgpt2\n",
            "[2021-09-09 13:54:40,915] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2021-09-09 13:54:40,915] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2021-09-09 13:54:40,915] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2021-09-09 13:54:40,915] [INFO] [launch.py:102:main] dist_world_size=1\n",
            "[2021-09-09 13:54:40,915] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "usage: train.py [-h] [--model_select MODEL_SELECT]\n",
            "                [--dataset_name DATASET_NAME]\n",
            "                [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
            "                [--dev_batch_size DEV_BATCH_SIZE]\n",
            "                [--num_epochs_train NUM_EPOCHS_TRAIN]\n",
            "                [--max_seq_length MAX_SEQ_LENGTH] [--lr LR]\n",
            "                [--warmup_ratio WARMUP_RATIO] [--early_stop EARLY_STOP]\n",
            "                [--scheduler SCHEDULER] [--seed SEED]\n",
            "                [--accumulation_steps ACCUMULATION_STEPS] [--n_gpu N_GPU]\n",
            "                [--visiable_device VISIABLE_DEVICE]\n",
            "                [--evaluation_steps EVALUATION_STEPS]\n",
            "                [--wandb_project_name WANDB_PROJECT_NAME] [--restore_training]\n",
            "                [--with_wandb]\n",
            "train.py: error: unrecognized arguments: --local_rank=0\n",
            "Killing subprocess 964\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 171, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 161, in main\n",
            "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 139, in sigkill_handler\n",
            "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'train.py', '--local_rank=0', '--model_select', 'distilgpt2']' returned non-zero exit status 2.\n"
          ]
        }
      ]
    }
  ]
}